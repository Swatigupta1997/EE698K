{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import PIL\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torchvision.utils\n",
    "import torch.utils.data\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import misc\n",
    "from matplotlib import pyplot as plt\n",
    "# sys.path.append('yourdir/pretrained-models.pytorch') # if needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDATA(torch.utils.data.Dataset): # Extend PyTorch's Dataset class\n",
    "    def __init__(self, root_dir, train, transform=None):\n",
    "        # root_dir  - the root directory of the dataset\n",
    "        # train     - a boolean parameter representing whether to return the training set or the test set\n",
    "        # transform - the transforms to be applied on the images before returning them\n",
    "        #\n",
    "        # In this function store the parameters in instance variables and make a mapping\n",
    "        # from images to labels and keep it as an instance variable. Make sure to check which\n",
    "        # dataset is required; train or test; and create the mapping accordingly.\n",
    "        if train:\n",
    "            cwd=root_dir+\"/train\"\n",
    "        else :\n",
    "            cwd=root_dir+\"/test\"\n",
    "        sub_dir=os.listdir(cwd)\n",
    "#         print(sub_dir)\n",
    "#         input()\n",
    "        self.imgAdd=[]\n",
    "        self.custom_transform=transform\n",
    "        self.imgAdd = [(cwd+\"/\"+image) for image in os.listdir(cwd)]\n",
    "        self.LABEL=[]\n",
    "#         print((self.imgAdd[0]))\n",
    "        \n",
    "# #             print(len(self.LABEL))\n",
    "#         print(((self.imgAdd[0].split(\".\")[0]).split(\"/\")[-1])[1:])\n",
    "#         input()\n",
    "    def __len__(self):\n",
    "        # return the size of the dataset (total number of images) as an integer\n",
    "        # this should be rather easy if you created a mapping in __init__\n",
    "        return len(self.imgAdd)\n",
    "    def __getitem__(self, idx):\n",
    "        lbl=[]\n",
    "        salImg = cv2.imread(self.imgAdd[idx],0)\n",
    "        rawDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/rawImgs/\"\n",
    "        name_rawImg = rawDir+((self.imgAdd[idx].split(\".\")[0]).split(\"/\")[-1])[1:]+\".jpg\" \n",
    "#         salImg = cv2.imread(salDir+file,0)\n",
    "        origImg = cv2.imread(name_rawImg)\n",
    "        imgS = cv2.resize(salImg,(150,150))\n",
    "        imgO1 = cv2.resize(origImg,(150,150))\n",
    "    \n",
    "        W=150\n",
    "        H=150\n",
    "        numPatches = 5\n",
    "\n",
    "        YcoorP,XcoorP = np.nonzero(imgS>255*0.9)\n",
    "        YcoorP = YcoorP[YcoorP>21]\n",
    "        XcoorP = XcoorP[XcoorP>21]\n",
    "        YcoorP = YcoorP[YcoorP<H-21]\n",
    "        XcoorP = XcoorP[XcoorP<W-21]\n",
    "#         print(XcoorP.size)\n",
    "#         input()\n",
    "        XcoorP = XcoorP[np.random.randint(XcoorP.shape[0], size=numPatches)]\n",
    "        YcoorP = YcoorP[np.random.randint(YcoorP.shape[0], size=numPatches)]\n",
    "\n",
    "        YcoorN,XcoorN = np.nonzero(imgS<255*0.1)\n",
    "        YcoorN = YcoorN[YcoorN>21]\n",
    "        XcoorN = XcoorN[XcoorN>21]\n",
    "        YcoorN = YcoorN[YcoorN<H-21]\n",
    "        XcoorN = XcoorN[XcoorN<W-21]\n",
    "        XcoorN = XcoorN[np.random.randint(XcoorN.shape[0], size=numPatches)]\n",
    "        YcoorN = YcoorN[np.random.randint(YcoorN.shape[0], size=numPatches)]\n",
    "\n",
    "        label =[]\n",
    "        labelP =[]\n",
    "        labelN =[]\n",
    "        scale = [(150,150),(250,250),(400,400)]\n",
    "        imgO2 = cv2.resize(origImg,scale[1])\n",
    "        imgO3 = cv2.resize(origImg,scale[2])\n",
    "        imgArray = [imgO1,imgO2,imgO3]\n",
    "        for k in range(3):\n",
    "#             print(\"k = \",k)\n",
    "#             print(\"scale[k] = \",scale[k])\n",
    "            ycoorP = (YcoorP*(scale[k][0]/150)).astype(np.int16)\n",
    "            xcoorP = (XcoorP*(scale[k][0]/150)).astype(np.int16)\n",
    "            ycoorN = (YcoorN*(scale[k][0]/150)).astype(np.int16)\n",
    "            xcoorN = (XcoorN*(scale[k][0]/150)).astype(np.int16)\n",
    "            if k==2:\n",
    "                print(xcoorP.min(),xcoorP.max())\n",
    "            stack = []\n",
    "            imgO = imgArray[k]\n",
    "            for i in range(5):\n",
    "                \n",
    "                patchP1 = imgO[ycoorP[i]-21:ycoorP[i]+21,xcoorP[i]-21:xcoorP[i]+21]\n",
    "                cv2.imwrite(\"temPatchP.png\",patchP1)\n",
    "#                 if k==2:\n",
    "#                     print(\"patchp1.shape = \",patchP1.shape)\n",
    "#                     input()\n",
    "                patchP1 = PIL.Image.open(\"temPatchP.png\")\n",
    "                patchP2 = PIL.ImageOps.mirror(patchP1)\n",
    "                \n",
    "                patchN1 = imgO[ycoorN[i]-21:ycoorN[i]+21,xcoorN[i]-21:xcoorN[i]+21]\n",
    "                cv2.imwrite(\"temPatchN.png\",patchN1)\n",
    "                patchN1 = PIL.Image.open(\"temPatchN.png\")\n",
    "                patchN2 = PIL.ImageOps.mirror(patchN1)\n",
    "\n",
    "                if self.custom_transform is not None:\n",
    "                    patchP1 = self.custom_transform(patchP1).unsqueeze_(0)\n",
    "                    patchP2 = self.custom_transform(patchP2).unsqueeze_(0)\n",
    "                    patchN1 = self.custom_transform(patchN1).unsqueeze_(0)\n",
    "                    patchN2 = self.custom_transform(patchN2).unsqueeze_(0)\n",
    "#                 print(\"patchP1.shape = \",patchP1.size())\n",
    "#                 input()\n",
    "                if i==0:\n",
    "                    stack = torch.cat((patchP1,patchP2,patchN1,patchN2),0)\n",
    "                    \n",
    "#                     label.append(0)\n",
    "#                     print(\"stack.shape = \",stack.size())\n",
    "#                     input()\n",
    "                else :\n",
    "                    stack = torch.cat((stack,patchP1,patchP2,patchN1,patchN2),0)\n",
    "                if k==0:\n",
    "                    label.append(1)\n",
    "                    label.append(1)\n",
    "                    label.append(0)\n",
    "                    label.append(0)\n",
    "#             print(\"stack.shape = \",stack.size())\n",
    "#             print('lbl = ',label)\n",
    "#             input()\n",
    "            stack.unsqueeze_(0)\n",
    "            if k==0:\n",
    "                kstack = stack\n",
    "            else:\n",
    "                kstack = torch.cat((kstack,stack),0)\n",
    "\n",
    "#         print(\"patch,shape = \",kstack.shape)\n",
    "#         print(\"label len = \",len(label))\n",
    "#         input()    \n",
    "\n",
    "        return kstack,label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: 100\n",
      "Size of test dataset: 20\n",
      "178 192\n"
     ]
    }
   ],
   "source": [
    "composed_transform = transforms.Compose([transforms.Scale((42,42)),transforms.ToTensor()])\n",
    "train_dataset = CDATA(root_dir='/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/salImgs', train=True, transform=composed_transform) # Supply proper root_dir\n",
    "test_dataset = CDATA(root_dir='/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/salImgs', train=False, transform=composed_transform) # Supply proper root_dir\n",
    "\n",
    "# Let's check the size of the datasets, if implemented correctly they should be 16854 and 1870 respectively\n",
    "print('Size of train dataset: %d' % len(train_dataset))\n",
    "print('Size of test dataset: %d'% len(test_dataset))\n",
    "\n",
    "# Create loaders for the dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Let's look at one batch of train and test images\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "train_dataiter = iter(train_loader)\n",
    "train_images, train_labels = train_dataiter.next()\n",
    "# print(\"Train images\")\n",
    "# imshow(torchvision.utils.make_grid(train_images))\n",
    "# # input()\n",
    "# test_dataiter = iter(test_loader)\n",
    "# test_images, test_labels = test_dataiter.next()\n",
    "# print(\"Test images\")\n",
    "# imshow(torchvision.utils.make_grid(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MRCNN(nn.Module): # Extend PyTorch's Module class\n",
    "    def __init__(self):\n",
    "        super(MRCNN, self).__init__() # Must call super __init__()\n",
    "        \n",
    "        # Define the layers of the network here\n",
    "        # There should be 17 total layers as evident from the diagram\n",
    "        # The parameters and names for the layers are provided in the diagram\n",
    "        # The variable names have to be the same as the ones in the diagram\n",
    "        # Otherwise, the weights will not load\n",
    "        self.conv1 = nn.Conv2d(3,96, kernel_size=7, stride=1,padding=0, bias=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2,padding=0)\n",
    "        self.conv2 = nn.Conv2d(96,160, kernel_size=3, stride=1,padding=0, bias=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2,padding=0)\n",
    "        self.conv3 = nn.Conv2d(160,288,kernel_size=3, stride=1, padding=0)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(2592, 512)\n",
    "        self.fc2 = nn.Linear(2592, 512)\n",
    "        self.fc3 = nn.Linear(2592, 512)\n",
    "        self.fc4 = nn.Linear(1536,1)\n",
    "        self.seq1 = nn.Sequential(self.conv1,self.maxpool1,\n",
    "                                 self.conv2,self.maxpool2,\n",
    "                                 self.conv3,self.maxpool3)\n",
    "        self.seq2 = nn.Sequential(self.conv1,self.maxpool1,\n",
    "                                 self.conv2,self.maxpool2,\n",
    "                                 self.conv3,self.maxpool3)\n",
    "        self.seq3 = nn.Sequential(self.conv1,self.maxpool1,\n",
    "                                 self.conv2,self.maxpool2,\n",
    "                                 self.conv3,self.maxpool3)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Here you have to define the forward pass\n",
    "        # Make sure you take care of the skip connections\n",
    "        x1 = x[:,0,:,:,:]\n",
    "        x2 = x[:,1,:,:,:]\n",
    "        x3 = x[:,2,:,:,:]\n",
    "        out1 = self.seq1(x1)\n",
    "        out2 = self.seq2(x2)\n",
    "        out3 = self.seq3(x3)\n",
    "        out1 = out1.view(-1, out1.numel())\n",
    "        out2 = out2.view(-1, out2.numel())\n",
    "        out3 = out3.view(-1, out3.numel())\n",
    "#         print(out1.size())\n",
    "#         out = tempout.view(-1, tempout.numel())\n",
    "#         print(out2.size())\n",
    "#         print(out3.size())\n",
    "#         input()\n",
    "        out1 = self.fc1(out1)\n",
    "        out2 = self.fc2(out2)\n",
    "        out3 = self.fc3(out3)\n",
    "        out  = torch.cat((out1,out2,out3),1)\n",
    "#         print(\"out.size = \",out.size())\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "    \n",
    "    # conv2d(input, weight, bias, stride, padding, dilation, groups)\n",
    "    # x = torch.cat(x_1, x_2, [dimension]) returns a Tensor x which is the concatenation of Tensors x_1 and x_2 along dimension dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU accesible\n"
     ]
    }
   ],
   "source": [
    "model_2 = MRCNN()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU accesible\")\n",
    "#     vgg16=vgg16.cuda(0)\n",
    "    model_2=model_2.cuda(0)\n",
    "# model_2 = nn.DataParallel(model_2, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # Define cross-entropy loss\n",
    "# optimizer_vgg16 = optim.Adam(vgg16.parameters(), lr=learning_rate)# Use Adam optimizer, use learning_rate hyper parameter\n",
    "optimizer_model_2 =optim.Adam(model_2.parameters(), lr=learning_rate) # Use Adam optimizer, use learning_rate hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0\n",
      "208 218\n",
      "data.size =  torch.Size([1, 3, 20, 3, 42, 42])\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1503968623488/work/torch/lib/THC/generated/../generic/THCTensorMathPointwise.cu:313",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-108e614d860f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#         print('loss = ',loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#         input()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0moptimizer_model_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vijayraj/anaconda3/envs/CV2/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vijayraj/anaconda3/envs/CV2/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vijayraj/anaconda3/envs/CV2/lib/python3.5/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vijayraj/anaconda3/envs/CV2/lib/python3.5/site-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# apply returns grad_input, so we need to return Nones for target (1) + 1 for each extra arg passed to forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         return ((backward_cls.apply(input, target, grad_output, ctx.additional_args, ctx._backend),) +\n\u001b[0m\u001b[1;32m     55\u001b[0m                 (None,) * (ctx.forward_args_count + 1))\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vijayraj/anaconda3/envs/CV2/lib/python3.5/site-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mbackward_cls_forward\u001b[0;34m(ctx, input, target, grad_output, additional_args_ctx, backend_ctx)\u001b[0m\n\u001b[1;32m     64\u001b[0m                                                       grad_input, *ctx.additional_args)\n\u001b[1;32m     65\u001b[0m         \u001b[0mgrad_output_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mgrad_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output_expanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1503968623488/work/torch/lib/THC/generated/../generic/THCTensorMathPointwise.cu:313"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    print(\"epoch = \",epoch)\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "    #             print(i)\n",
    "    ### assume that data is in the form of 10 rgb images i.e. 10*3*H*W \n",
    "        count+=1\n",
    "        inputs, labels = data\n",
    "        print(\"data.size = \",inputs.size())\n",
    "        input()\n",
    "#         labels=labels.long()\n",
    "        # zero the parameter gradients\n",
    "        for j in range(20):\n",
    "#             ip1 = inputs[:,0,i,:,:,:]\n",
    "#             ip2 = inputs[:,1,i,:,:,:]\n",
    "#             ip3 = inputs[:,2,i,:,:,:]\n",
    "            ip = inputs[:,:,i,:,:,:]\n",
    "            \n",
    "            ip = Variable(ip).cuda()\n",
    "            label = labels[i].long()\n",
    "            label = Variable(label).cuda() \n",
    "            \n",
    "            optimizer_model_2.zero_grad()\n",
    "\n",
    "#             ip1,ip2,ip3, label = Variable(ip1).cuda(),Variable(ip2).cuda(),Variable(ip3).cuda(), Variable(label).cuda()\n",
    "#             output1 = model_2(ip1)\n",
    "#                     = \n",
    "            output = model_2(ip)\n",
    "#             print(\"output.size = \",output)\n",
    "#             input()\n",
    "#         # forward + backward + optimize\n",
    "#             if img_indx ==0 :\n",
    "#                 output = resnet18(img)\n",
    "#             else :\n",
    "#                 output = np.vstack((output,resnet18(img))\n",
    "        \n",
    "            loss = criterion(output, label)\n",
    "#         print('loss = ',loss)\n",
    "#         input()\n",
    "            loss.backward()\n",
    "            optimizer_model_2.step()\n",
    "\n",
    "        # print statistics\n",
    "            running_loss +=loss\n",
    "            loss_numpy=loss.cpu().data.numpy()        \n",
    "            epoch_loss +=loss_numpy\n",
    "    #             if count%100==0:\n",
    "    #                 print(\"count = \",count)\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d]  '%\n",
    "                  (epoch + 1, i + 1, ))\n",
    "            print(\"running loss = \",running_loss/500)\n",
    "            running_loss = 0.0\n",
    "            count=0\n",
    "\n",
    "    epoch_lossArray.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 400\n",
    "Ylist = np.arange(0,400-42)\n",
    "Xlist = np.arange(0,400-42)\n",
    "xcoor = np.random.randint(42,400-42,10)\n",
    "ycoor = np.random.randint(42,400-42,10)\n",
    "\n",
    "for i in range(10):\n",
    "    Xlist[xcoor[i]-21:xcoor[i]+21] = 0\n",
    "    Ylist[ycoor[i]-21:ycoor[i]+21] = 0\n",
    "Xlist = np.unique(Xlist)\n",
    "Ylist = np.unique(Ylist)\n",
    "Xlist = Xlist[Xlist>=21]\n",
    "# for i in range(10):\n",
    "#     print(np.isin(np.arange(xcoor[i]-21,xcoor[i]+21),Xlist))\n",
    "# plt.plot(Xlist)\n",
    "# plt.show()\n",
    "print(Xlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "salDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/salImgs/\"\n",
    "rawDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/rawImgs/\"\n",
    "imgfiles=[]\n",
    "imgfiles2=[]\n",
    "imgfiles += [each for each in os.listdir(salDir) if each.endswith('.jpg')]\n",
    "imgfiles2 += [each for each in os.listdir(\"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/rawImgs\") if each.endswith('.jpg')]\n",
    "print(imgfiles[0].split(\".\")[0][1:])\n",
    "\n",
    "# input()\n",
    "count = 0\n",
    "numPatches=5\n",
    "for file in imgfiles:\n",
    "    salImg = cv2.imread(salDir+file,0)\n",
    "    origImg = cv2.imread(rawDir+file.split(\".\")[0][1:]+\".jpg\")\n",
    "    imgS = cv2.resize(salImg,(150,150))\n",
    "    imgO1 = cv2.resize(origImg,(150,150))\n",
    "#     cv2.imshow(\"orig\",origImg)\n",
    "#     for j in [(400,400),(250,250),(150,150)]:\n",
    "#         print(j)\n",
    "    W=150\n",
    "        \n",
    "#         print(imgS.shape)\n",
    "    \n",
    "    YcoorP,XcoorP = np.nonzero(imgS>255*0.9)\n",
    "    print(XcoorP.size)\n",
    "    input()\n",
    "    YcoorP = YcoorP[YcoorP>21]\n",
    "    XcoorP = XcoorP[XcoorP>21]\n",
    "    print(XcoorP.size)\n",
    "    YcoorP = YcoorP[YcoorP<H-21]\n",
    "    XcoorP = XcoorP[XcoorP<W-21]\n",
    "    print(XcoorP.size)\n",
    "    input()\n",
    "    XcoorP = XcoorP[np.random.randint(XcoorP.shape[0], size=numPatches)]\n",
    "    YcoorP = YcoorP[np.random.randint(YcoorP.shape[0], size=numPatches)]\n",
    "    \n",
    "    YcoorN,XcoorN = np.nonzero(imgS<255*0.1)\n",
    "    YcoorN = YcoorN[YcoorN>21]\n",
    "    XcoorN = XcoorN[XcoorN>21]\n",
    "    YcoorN = YcoorN[YcoorN<H-21]\n",
    "    XcoorN = XcoorN[XcoorN<W-21]\n",
    "    XcoorN = XcoorN[np.random.randint(XcoorN.shape[0], size=numPatches)]\n",
    "    YcoorN = YcoorN[np.random.randint(YcoorN.shape[0], size=numPatches)]\n",
    "\n",
    "    label =[]\n",
    "    labelP =[]\n",
    "    labelN =[]\n",
    "    scale = [(150,150),(250,250),(400,400)]\n",
    "    imgO2 = cv2.resize(origImg,scale[1])\n",
    "    imgO3 = cv2.resize(origImg,scale[2])\n",
    "    imgArray = [imgO1,imgO2,imgO3]\n",
    "    for k in range(3):\n",
    "        \n",
    "        ycoorP = (YcoorP*scale[k][0]/150).astype(np.int8)\n",
    "        xcoorP = (XcoorP*scale[k][0]/150).astype(np.int8)\n",
    "        ycoorN = (YcoorN*scale[k][0]/150).astype(np.int8)\n",
    "        xcoorN = (XcoorN*scale[k][0]/150).astype(np.int8)\n",
    "        stack = []\n",
    "        imgO = imgArray[k]\n",
    "        for i in range(5):\n",
    "            \n",
    "            patchP1 = imgO[ycoorP[i]-21:ycoorP[i]+21,xcoorP[i]-21:xcoorP[i]+21]\n",
    "            patchP2 = cv2.flip(patchP1,0)\n",
    "            patchN1 = imgO[ycoorN[i]-21:ycoorN[i]+21,xcoorN[i]-21:xcoorN[i]+21]\n",
    "            patchN2 = cv2.flip(patchN1,0)\n",
    "            patchN1 = patchN1[np.newaxis,...]\n",
    "            patchN2 = patchN2[np.newaxis,...]\n",
    "            patchP1 = patchP1[np.newaxis,...]\n",
    "            patchP2 = patchP2[np.newaxis,...]\n",
    "            if i==0:\n",
    "                stack = np.concatenate((patchP1,patchP2),axis = 0)\n",
    "                stack = np.concatenate((stack,patchN1),axis = 0)\n",
    "                stack = np.concatenate((stack,patchN2),axis = 0)\n",
    "                label.append(1)\n",
    "                label.append(1)\n",
    "                label.append(0)\n",
    "                label.append(0)\n",
    "            else :\n",
    "                stack = np.concatenate((stack,patchP1),axis = 0)\n",
    "                stack = np.concatenate((stack,patchP2),axis = 0)\n",
    "                stack = np.concatenate((stack,patchN1),axis = 0)\n",
    "                stack = np.concatenate((stack,patchN2),axis = 0)\n",
    "                label.append(1)\n",
    "                label.append(1)\n",
    "                label.append(0)\n",
    "                label.append(0)\n",
    "        stack = (np.concatenate((Pstack,Nstack),axis= 0))[np.newaxis,...]\n",
    "        if k==0:\n",
    "            kstack = stack\n",
    "        else:\n",
    "            kstack = np.concatenate((kstack,stack),axis = 0)\n",
    "            \n",
    "    print(\"patch,shape = \",kstack.shape)\n",
    "    print(\"label len = \",len(label))\n",
    "    input()\n",
    "#             if count<=6480:\n",
    "#                 saveDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/\"\n",
    "#             else :\n",
    "#                 saveDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/\"\n",
    "                \n",
    "#             cv2.imwrite(saveDir + \"/1/\"+\"patchP_\"+str(count)+\".png\",patchP1)\n",
    "#             cv2.imwrite(saveDir + \"/0/\"+\"patchN_\"+str(count)+\".png\",patchN1)\n",
    "#             cv2.imwrite(saveDir + \"/1/\"+\"patchP_\"+str(count+1)+\".png\",patchP2)\n",
    "#             cv2.imwrite(saveDir + \"/0/\"+\"patchN_\"+str(count+1)+\".png\",patchN2)\n",
    "#             count= count+2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5112*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(25)\n",
    "a= a[a>15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
