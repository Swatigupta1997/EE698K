{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import PIL\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torchvision.utils\n",
    "import torch.utils.data\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import misc\n",
    "from matplotlib import pyplot as plt\n",
    "# sys.path.append('yourdir/pretrained-models.pytorch') # if needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CDATA(torch.utils.data.Dataset): # Extend PyTorch's Dataset class\n",
    "    def __init__(self, root_dir, train, transform=None):\n",
    "        # root_dir  - the root directory of the dataset\n",
    "        # train     - a boolean parameter representing whether to return the training set or the test set\n",
    "        # transform - the transforms to be applied on the images before returning them\n",
    "        #\n",
    "        # In this function store the parameters in instance variables and make a mapping\n",
    "        # from images to labels and keep it as an instance variable. Make sure to check which\n",
    "        # dataset is required; train or test; and create the mapping accordingly.\n",
    "        if train:\n",
    "            cwd=root_dir+\"/train\"\n",
    "        else :\n",
    "            cwd=root_dir+\"/test\"\n",
    "        sub_dir=os.listdir(cwd)\n",
    "#         print(sub_dir)\n",
    "#         input()\n",
    "        self.imgAdd=[]\n",
    "        self.custom_transform=transform\n",
    "        for i in range(len(sub_dir)):\n",
    "            directory=cwd+\"/\" + sub_dir[i]\n",
    "            filelist=[(directory+\"/\"+image) for image in os.listdir(directory)] \n",
    "#             print(filelist[:5])\n",
    "#             input()\n",
    "            label =np.ones(len(filelist),np.uint8)*int(sub_dir[i])\n",
    "#             print(label)\n",
    "#             input()\n",
    "#             print(labe?l[0])\n",
    "            if i==0:\n",
    "                self.imgAdd= self.imgAdd+filelist\n",
    "                self.LABEL=label\n",
    "\n",
    "            else:\n",
    "                self.imgAdd= self.imgAdd+filelist\n",
    "                self.LABEL=np.hstack((self.LABEL,label))\n",
    "            print(len(self.imgAdd))\n",
    "            print(len(self.LABEL))\n",
    "#             input()\n",
    "    def __len__(self):\n",
    "        # return the size of the dataset (total number of images) as an integer\n",
    "        # this should be rather easy if you created a mapping in __init__\n",
    "        return self.LABEL.size\n",
    "    def __getitem__(self, idx):\n",
    "        # idx - the index of the sample requested\n",
    "        #\n",
    "        # Open the image correspoding to idx, apply transforms on it and return a tuple (image, label)\n",
    "        # where label is an integer from 0-9 (since notMNIST has 10 classes)\n",
    "        \n",
    "        img=PIL.Image.open(self.imgAdd[idx])\n",
    "        \n",
    "#         print((self.LABEL[0]))\n",
    "        lbl=(self.LABEL[idx])\n",
    "        if self.custom_transform is not None:\n",
    "            img = self.custom_transform(img)\n",
    "#             img=torch.cat((img,img,img),0)\n",
    "#             print(img.shape)\n",
    "#             input()\n",
    "#         print(len(self.imgAdd))\n",
    "        \n",
    "        return img,lbl\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '0']\n",
      "\n",
      "['/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/1/patchP_6138.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/1/patchP_6215.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/1/patchP_4798.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/1/patchP_4102.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/1/patchP_2318.jpg']\n",
      "\n",
      "[1 1 1 ... 1 1 1]\n",
      "\n",
      "6482\n",
      "6482\n",
      "\n",
      "['/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/0/patchN_928.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/0/patchN_3258.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/0/patchN_2491.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/0/patchN_1166.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/0/patchN_3435.jpg']\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "12964\n",
      "12964\n",
      "\n",
      "['1', '0']\n",
      "\n",
      "['/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/1/patchP_7106.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/1/patchP_6549.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/1/patchP_6834.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/1/patchP_6488.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/1/patchP_6832.jpg']\n",
      "\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "718\n",
      "718\n",
      "\n",
      "['/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/0/patchN_6817.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/0/patchN_6545.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/0/patchN_6871.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/0/patchN_6557.jpg', '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/0/patchN_6787.jpg']\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "1436\n",
      "1436\n",
      "\n",
      "Size of train dataset: 12964\n",
      "Size of test dataset: 1436\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot identify image file '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/0/patchN_1915.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c0835106ca0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtrain_dataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vijayraj/anaconda3/envs/CV2/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vijayraj/anaconda3/envs/CV2/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-111637e55cee>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# where label is an integer from 0-9 (since notMNIST has 10 classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgAdd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#         print((self.LABEL[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vijayraj/anaconda3/envs/CV2/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2585\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file '/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/0/patchN_1915.jpg'"
     ]
    }
   ],
   "source": [
    "composed_transform = transforms.Compose([transforms.Scale((224,224)),transforms.ToTensor()])\n",
    "train_dataset = CDATA(root_dir='/home/vijayraj/Workspace/Acads/EE698K/Project/dataset', train=True, transform=composed_transform) # Supply proper root_dir\n",
    "test_dataset = CDATA(root_dir='/home/vijayraj/Workspace/Acads/EE698K/Project/dataset', train=False, transform=composed_transform) # Supply proper root_dir\n",
    "\n",
    "# Let's check the size of the datasets, if implemented correctly they should be 16854 and 1870 respectively\n",
    "print('Size of train dataset: %d' % len(train_dataset))\n",
    "print('Size of test dataset: %d'% len(test_dataset))\n",
    "\n",
    "# Create loaders for the dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Let's look at one batch of train and test images\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "train_dataiter = iter(train_loader)\n",
    "train_images, train_labels = train_dataiter.next()\n",
    "print(\"Train images\")\n",
    "imshow(torchvision.utils.make_grid(train_images))\n",
    "# input()\n",
    "test_dataiter = iter(test_loader)\n",
    "test_images, test_labels = test_dataiter.next()\n",
    "print(\"Test images\")\n",
    "imshow(torchvision.utils.make_grid(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MRCNN(nn.Module): # Extend PyTorch's Module class\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(CustomResnet, self).__init__() # Must call super __init__()\n",
    "        \n",
    "        # Define the layers of the network here\n",
    "        # There should be 17 total layers as evident from the diagram\n",
    "        # The parameters and names for the layers are provided in the diagram\n",
    "        # The variable names have to be the same as the ones in the diagram\n",
    "        # Otherwise, the weights will not load\n",
    "        self.conv1 = nn.Conv2d(3,96, kernel_size=7, stride=1,padding=0, bias=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2,padding=0)\n",
    "        self.conv2 = nn.Conv2d(96,160, kernel_size=3, stride=1,padding=0, bias=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2,padding=0)\n",
    "        sel.conv3 = nn.Conv2d(160,288,kernel_size=3, stride=1, padding=0)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=1, padding=0)\n",
    "        self.fc = nn.Linear(2592, 512)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Here you have to define the forward pass\n",
    "        # Make sure you take care of the skip connections\n",
    "        tempout = self.conv1(x)\n",
    "        tempout = self.maxpool1(tempout)\n",
    "        tempout = self.conv2(x)\n",
    "        tempout = self.maxpool2(tempout)\n",
    "        tempout = self.conv3(x)\n",
    "        tempout = self.maxpool3(tempout)\n",
    "        out = tempout.view(-1, tempout.numel())\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # conv2d(input, weight, bias, stride, padding, dilation, groups)\n",
    "    # x = torch.cat(x_1, x_2, [dimension]) returns a Tensor x which is the concatenation of Tensors x_1 and x_2 along dimension dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5aa58784a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38\n",
      "  39 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138\n",
      " 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357]\n"
     ]
    }
   ],
   "source": [
    "H = 400\n",
    "Ylist = np.arange(0,400-42)\n",
    "Xlist = np.arange(0,400-42)\n",
    "xcoor = np.random.randint(42,400-42,10)\n",
    "ycoor = np.random.randint(42,400-42,10)\n",
    "\n",
    "for i in range(10):\n",
    "    Xlist[xcoor[i]-21:xcoor[i]+21] = 0\n",
    "    Ylist[ycoor[i]-21:ycoor[i]+21] = 0\n",
    "Xlist = np.unique(Xlist)\n",
    "Ylist = np.unique(Ylist)\n",
    "Xlist = Xlist[Xlist>=21]\n",
    "# for i in range(10):\n",
    "#     print(np.isin(np.arange(xcoor[i]-21,xcoor[i]+21),Xlist))\n",
    "plt.plot(Xlist)\n",
    "plt.show()\n",
    "print(Xlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "\n",
      "26\n",
      "48\n",
      "11\n",
      "2\n",
      "86\n",
      "73\n",
      "114\n",
      "107\n",
      "13\n",
      "108\n",
      "47\n",
      "101\n",
      "38\n",
      "104\n",
      "43\n",
      "51\n",
      "102\n",
      "96\n",
      "93\n",
      "70\n",
      "21\n",
      "118\n",
      "88\n",
      "54\n",
      "111\n",
      "74\n",
      "35\n",
      "65\n",
      "76\n",
      "41\n",
      "34\n",
      "106\n",
      "63\n",
      "53\n",
      "4\n",
      "119\n",
      "37\n",
      "14\n",
      "79\n",
      "39\n",
      "82\n",
      "25\n",
      "58\n",
      "40\n",
      "12\n",
      "27\n",
      "32\n",
      "42\n",
      "78\n",
      "66\n",
      "23\n",
      "64\n",
      "8\n",
      "45\n",
      "89\n",
      "1\n",
      "68\n",
      "59\n",
      "22\n",
      "100\n",
      "33\n",
      "61\n",
      "80\n",
      "60\n",
      "10\n",
      "18\n",
      "5\n",
      "49\n",
      "44\n",
      "16\n",
      "20\n",
      "75\n",
      "113\n",
      "31\n",
      "50\n",
      "67\n",
      "90\n",
      "92\n",
      "30\n",
      "110\n",
      "87\n",
      "97\n",
      "56\n",
      "17\n",
      "94\n",
      "72\n",
      "46\n",
      "62\n",
      "109\n",
      "28\n",
      "120\n",
      "71\n",
      "29\n",
      "36\n",
      "116\n",
      "55\n",
      "52\n",
      "3\n",
      "98\n",
      "115\n",
      "9\n",
      "6\n",
      "57\n",
      "95\n",
      "15\n",
      "83\n",
      "91\n",
      "7\n",
      "19\n",
      "24\n",
      "112\n",
      "84\n",
      "81\n",
      "85\n",
      "69\n",
      "103\n",
      "117\n",
      "77\n",
      "99\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "\n",
    "salDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/salImgs/\"\n",
    "rawDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/rawImgs/\"\n",
    "imgfiles=[]\n",
    "imgfiles2=[]\n",
    "imgfiles += [each for each in os.listdir(salDir) if each.endswith('.jpg')]\n",
    "imgfiles2 += [each for each in os.listdir(\"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/rawImgs\") if each.endswith('.jpg')]\n",
    "print(imgfiles[0].split(\".\")[0][1:])\n",
    "\n",
    "# input()\n",
    "count = 0\n",
    "for file in imgfiles:\n",
    "    salImg = cv2.imread(salDir+file,0)\n",
    "    origImg = cv2.imread(rawDir+file.split(\".\")[0][1:]+\".jpg\")\n",
    "#     cv2.imshow(\"orig\",origImg)\n",
    "#     cv2.waitKey(10)\n",
    "#     print(file.split(\".\")[0][1:])\n",
    "#     input()\n",
    "    for j in [(400,400),(250,250),(150,150)]:\n",
    "#         print(j)\n",
    "        imgS = cv2.resize(salImg,j)\n",
    "        imgO = cv2.resize(origImg,j)\n",
    "#         print(imgS.shape)\n",
    "    \n",
    "        ycoorP,xcoorP = np.nonzero(imgS>255*0.9)\n",
    "        xcoorP = xcoorP[np.random.randint(xcoorP.shape[0], size=10)]\n",
    "        ycoorP = ycoorP[np.random.randint(ycoorP.shape[0], size=10)]\n",
    "        ycoorN,xcoorN = np.nonzero(imgS<255*0.1)\n",
    "        xcoorN = xcoorN[np.random.randint(xcoorN.shape[0], size=10)]\n",
    "        ycoorN = ycoorN[np.random.randint(ycoorN.shape[0], size=10)]\n",
    "#     H = 400\n",
    "#     Ylist = np.arange(0,400-42)\n",
    "#     Xlist = np.arange(0,400-42)\n",
    "#     xcoor = np.random.randint(42,400-42,10)\n",
    "#     ycoor = np.random.randint(42,400-42,10)\n",
    "    # function to get xcoorP and ycoorP\n",
    "#     for i in range(10):\n",
    "#         Xlist[xcoorP[i]-21:xcoorP[i]+21] = 0\n",
    "#         Ylist[ycoorP[i]-21:ycoorP[i]+21] = 0\n",
    "#     Xlist = np.unique(Xlist)\n",
    "#     Ylist = np.unique(Ylist)\n",
    "#     Xlist = Xlist[Xlist>=21]\n",
    "#     Ylist = ylist[Ylist>=21]\n",
    "#     xcoorN = np.random.sample(Xlist,10)\n",
    "#     ycoorN = np.random.sample(Ylist,10)\n",
    "        for i in range(10):\n",
    "            patchP1 = imgO[ycoorP[i]-21:ycoorP[i]+21,xcoorP[i]-21:xcoorP[i]+21]\n",
    "            patchP2 = cv2.flip(patchP1,0)\n",
    "            patchN1 = imgO[ycoorN[i]-21:ycoorN[i]+21,xcoorN[i]-21:xcoorN[i]+21]\n",
    "            patchN2 = cv2.flip(patchN1,0)\n",
    "            if count<=6480:\n",
    "                saveDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/\"\n",
    "            else :\n",
    "                saveDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/\"\n",
    "                \n",
    "            cv2.imwrite(saveDir + \"/1/\"+\"patchP_\"+str(count)+\".png\",patchP1)\n",
    "            cv2.imwrite(saveDir + \"/0/\"+\"patchN_\"+str(count)+\".png\",patchN1)\n",
    "            cv2.imwrite(saveDir + \"/1/\"+\"patchP_\"+str(count+1)+\".png\",patchP2)\n",
    "            cv2.imwrite(saveDir + \"/0/\"+\"patchN_\"+str(count+1)+\".png\",patchN2)\n",
    "            count= count+2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xlist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-af0521ab665b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Xlist' is not defined"
     ]
    }
   ],
   "source": [
    "# np.random.random(Xlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2592"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*3*288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
