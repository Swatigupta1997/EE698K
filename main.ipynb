{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import PIL\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torchvision.utils\n",
    "import torch.utils.data\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import misc\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "# sys.path.append('yourdir/pretrained-models.pytorch') # if needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_epochs = 50\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CDATA(torch.utils.data.Dataset): # Extend PyTorch's Dataset class\n",
    "    def __init__(self, root_dir, train, transform=None):\n",
    "        # root_dir  - the root directory of the dataset\n",
    "        # train     - a boolean parameter representing whether to return the training set or the test set\n",
    "        # transform - the transforms to be applied on the images before returning them\n",
    "        #\n",
    "        # In this function store the parameters in instance variables and make a mapping\n",
    "        # from images to labels and keep it as an instance variable. Make sure to check which\n",
    "        # dataset is required; train or test; and create the mapping accordingly.\n",
    "        if train:\n",
    "            cwd=root_dir+\"/train\"\n",
    "        else :\n",
    "            cwd=root_dir+\"/test\"\n",
    "        sub_dir=os.listdir(cwd)\n",
    "#         print(sub_dir)\n",
    "#         input()\n",
    "        self.imgAdd=[]\n",
    "        self.custom_transform=transform\n",
    "        self.imgAdd = [(cwd+\"/\"+image) for image in os.listdir(cwd)]\n",
    "        self.LABEL=[]\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the size of the dataset (total number of images) as an integer\n",
    "        # this should be rather easy if you created a mapping in __init__\n",
    "        return len(self.imgAdd)\n",
    "    def __getitem__(self, idx):\n",
    "        lbl=[]\n",
    "        salImg = cv2.imread(self.imgAdd[idx],0)\n",
    "        rawDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/rawImgs/\"\n",
    "        name_rawImg = rawDir+((self.imgAdd[idx].split(\".\")[0]).split(\"/\")[-1])[1:]+\".jpg\" \n",
    "#         salImg = cv2.imread(salDir+file,0)\n",
    "        origImg = cv2.imread(name_rawImg)\n",
    "        imgS = cv2.resize(salImg,(150,150))\n",
    "        imgO1 = cv2.resize(origImg,(150,150))\n",
    "    \n",
    "        W=150\n",
    "        H=150\n",
    "        numPatches = 5\n",
    "\n",
    "        YcoorP,XcoorP = np.nonzero(imgS>255*0.9)\n",
    "        YcoorP = YcoorP[YcoorP>21]\n",
    "        XcoorP = XcoorP[XcoorP>21]\n",
    "        YcoorP = YcoorP[YcoorP<H-21]\n",
    "        XcoorP = XcoorP[XcoorP<W-21]\n",
    "        XcoorP = XcoorP[np.random.randint(XcoorP.shape[0], size=numPatches)]\n",
    "        YcoorP = YcoorP[np.random.randint(YcoorP.shape[0], size=numPatches)]\n",
    "\n",
    "        YcoorN,XcoorN = np.nonzero(imgS<255*0.1)\n",
    "        YcoorN = YcoorN[YcoorN>21]\n",
    "        XcoorN = XcoorN[XcoorN>21]\n",
    "        YcoorN = YcoorN[YcoorN<H-21]\n",
    "        XcoorN = XcoorN[XcoorN<W-21]\n",
    "        XcoorN = XcoorN[np.random.randint(XcoorN.shape[0], size=numPatches)]\n",
    "        YcoorN = YcoorN[np.random.randint(YcoorN.shape[0], size=numPatches)]\n",
    "\n",
    "        label =[]\n",
    "        labelP =[]\n",
    "        labelN =[]\n",
    "        scale = [(150,150),(250,250),(400,400)]\n",
    "        imgO2 = cv2.resize(origImg,scale[1])\n",
    "        imgO3 = cv2.resize(origImg,scale[2])\n",
    "        imgArray = [imgO1,imgO2,imgO3]\n",
    "        for k in range(3):\n",
    "#             print(\"k = \",k)\n",
    "#             print(\"scale[k] = \",scale[k])\n",
    "            ycoorP = (YcoorP*(scale[k][0]/150)).astype(np.int16)\n",
    "            xcoorP = (XcoorP*(scale[k][0]/150)).astype(np.int16)\n",
    "            ycoorN = (YcoorN*(scale[k][0]/150)).astype(np.int16)\n",
    "            xcoorN = (XcoorN*(scale[k][0]/150)).astype(np.int16)\n",
    "#             if k==2:\n",
    "#                 print(xcoorP.min(),xcoorP.max())\n",
    "            stack = []\n",
    "            imgO = imgArray[k]\n",
    "            for i in range(5):\n",
    "                \n",
    "                patchP1 = imgO[ycoorP[i]-21:ycoorP[i]+21,xcoorP[i]-21:xcoorP[i]+21]\n",
    "                cv2.imwrite(\"temPatchP.png\",patchP1)\n",
    "#                 if k==2:\n",
    "#                     print(\"patchp1.shape = \",patchP1.shape)\n",
    "#                     input()\n",
    "                patchP1 = PIL.Image.open(\"temPatchP.png\")\n",
    "                patchP2 = PIL.ImageOps.mirror(patchP1)\n",
    "                \n",
    "                patchN1 = imgO[ycoorN[i]-21:ycoorN[i]+21,xcoorN[i]-21:xcoorN[i]+21]\n",
    "                cv2.imwrite(\"temPatchN.png\",patchN1)\n",
    "                patchN1 = PIL.Image.open(\"temPatchN.png\")\n",
    "                patchN2 = PIL.ImageOps.mirror(patchN1)\n",
    "\n",
    "                if self.custom_transform is not None:\n",
    "                    patchP1 = self.custom_transform(patchP1).unsqueeze_(0)\n",
    "                    patchP2 = self.custom_transform(patchP2).unsqueeze_(0)\n",
    "                    patchN1 = self.custom_transform(patchN1).unsqueeze_(0)\n",
    "                    patchN2 = self.custom_transform(patchN2).unsqueeze_(0)\n",
    "                if i==0:\n",
    "                    stack = torch.cat((patchP1,patchP2,patchN1,patchN2),0)\n",
    "                    \n",
    "#                    \n",
    "                else :\n",
    "                    stack = torch.cat((stack,patchP1,patchP2,patchN1,patchN2),0)\n",
    "                if k==0:\n",
    "                    label.append(1)\n",
    "                    label.append(1)\n",
    "                    label.append(0)\n",
    "                    label.append(0)\n",
    "#            \n",
    "            stack.unsqueeze_(0)\n",
    "            if k==0:\n",
    "                kstack = stack\n",
    "            else:\n",
    "                kstack = torch.cat((kstack,stack),0)\n",
    "\n",
    "#            \n",
    "\n",
    "        return kstack,label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: 100\n",
      "Size of test dataset: 20\n"
     ]
    }
   ],
   "source": [
    "composed_transform = transforms.Compose([transforms.Scale((42,42)),transforms.ToTensor()])\n",
    "train_dataset = CDATA(root_dir='/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/salImgs', train=True, transform=composed_transform) # Supply proper root_dir\n",
    "test_dataset = CDATA(root_dir='/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/salImgs', train=False, transform=composed_transform) # Supply proper root_dir\n",
    "\n",
    "# Let's check the size of the datasets, if implemented correctly they should be 16854 and 1870 respectively\n",
    "print('Size of train dataset: %d' % len(train_dataset))\n",
    "print('Size of test dataset: %d'% len(test_dataset))\n",
    "\n",
    "# Create loaders for the dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Let's look at one batch of train and test images\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "train_dataiter = iter(train_loader)\n",
    "train_images, train_labels = train_dataiter.next()\n",
    "# print(\"Train images\")\n",
    "# imshow(torchvision.utils.make_grid(train_images))\n",
    "# # input()\n",
    "# test_dataiter = iter(test_loader)\n",
    "# test_images, test_labels = test_dataiter.next()\n",
    "# print(\"Test images\")\n",
    "# imshow(torchvision.utils.make_grid(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MRCNN(nn.Module): # Extend PyTorch's Module class\n",
    "    def __init__(self):\n",
    "        super(MRCNN, self).__init__() # Must call super __init__()\n",
    "        \n",
    "        # Define the layers of the network here\n",
    "        # There should be 17 total layers as evident from the diagram\n",
    "        # The parameters and names for the layers are provided in the diagram\n",
    "        # The variable names have to be the same as the ones in the diagram\n",
    "        # Otherwise, the weights will not load\n",
    "        self.conv1 = nn.Conv2d(3,96, kernel_size=7, stride=1,padding=0, bias=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2,padding=0)\n",
    "        self.conv2 = nn.Conv2d(96,160, kernel_size=3, stride=1,padding=0, bias=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2,padding=0)\n",
    "        self.conv3 = nn.Conv2d(160,288,kernel_size=3, stride=1, padding=0)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(2592, 512)\n",
    "        self.fc2 = nn.Linear(2592, 512)\n",
    "        self.fc3 = nn.Linear(2592, 512)\n",
    "        self.fc4 = nn.Linear(1536,1)\n",
    "        self.seq1 = nn.Sequential(self.conv1,self.maxpool1,\n",
    "                                 self.conv2,self.maxpool2,\n",
    "                                 self.conv3,self.maxpool3)\n",
    "        self.seq2 = nn.Sequential(self.conv1,self.maxpool1,\n",
    "                                 self.conv2,self.maxpool2,\n",
    "                                 self.conv3,self.maxpool3)\n",
    "        self.seq3 = nn.Sequential(self.conv1,self.maxpool1,\n",
    "                                 self.conv2,self.maxpool2,\n",
    "                                 self.conv3,self.maxpool3)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Here you have to define the forward pass\n",
    "        # Make sure you take care of the skip connections\n",
    "        x1 = x[:,0,:,:,:].contiguous()\n",
    "        x2 = x[:,1,:,:,:].contiguous()\n",
    "        x3 = x[:,2,:,:,:].contiguous()\n",
    "        out1 = self.seq1(x1)\n",
    "        out2 = self.seq2(x2)\n",
    "        out3 = self.seq3(x3)\n",
    "        out1 = out1.view(-1, out1.numel())\n",
    "        out2 = out2.view(-1, out2.numel())\n",
    "        out3 = out3.view(-1, out3.numel())\n",
    "#         print(out1.size())\n",
    "#         out = tempout.view(-1, tempout.numel())\n",
    "#         print(out2.size())\n",
    "#         print(out3.size())\n",
    "#         input()\n",
    "        out1 = self.fc1(out1)\n",
    "        out2 = self.fc2(out2)\n",
    "        out3 = self.fc3(out3)\n",
    "        out  = torch.cat((out1,out2,out3),1)\n",
    "#         print(\"out.size = \",out.size())\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "    \n",
    "    # conv2d(input, weight, bias, stride, padding, dilation, groups)\n",
    "    # x = torch.cat(x_1, x_2, [dimension]) returns a Tensor x which is the concatenation of Tensors x_1 and x_2 along dimension dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU accesible\n"
     ]
    }
   ],
   "source": [
    "model_2 = MRCNN()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU accesible\")\n",
    "#     vgg16=vgg16.cuda(0)\n",
    "    model_2=model_2.cuda(0)\n",
    "# model_2 = nn.DataParallel(model_2, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() # Define cross-entropy loss\n",
    "# optimizer_vgg16 = optim.Adam(vgg16.parameters(), lr=learning_rate)# Use Adam optimizer, use learning_rate hyper parameter\n",
    "optimizer_model_2 =optim.Adam(model_2.parameters(), lr=learning_rate) # Use Adam optimizer, use learning_rate hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='trainedModel_Class5.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Variable objects containing non-empty torch.cuda.ByteTensor is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d36ef814a1e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m>=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vijayraj/anaconda3/envs/CV2/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         raise RuntimeError(\"bool value of Variable objects containing non-empty \" +\n\u001b[0;32m--> 123\u001b[0;31m                            torch.typename(self.data) + \" is ambiguous\")\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Variable objects containing non-empty torch.cuda.ByteTensor is ambiguous"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "epoch_lossArray =[]\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    print(\"epoch = \",epoch)\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "    #             print(i)\n",
    "    ### assume that data is in the form of 10 rgb images i.e. 10*3*H*W \n",
    "#         if i >=2 :continue\n",
    "        count+=1\n",
    "        inputs, labels = data\n",
    "#         print(\"data.size = \",inputs.size())\n",
    "#         print(labels)\n",
    "#         input()\n",
    "#         labels=labels.long()\n",
    "        # zero the parameter gradients\n",
    "        for j in range(20):\n",
    "#             if j>=4:continue\n",
    "#             print(\"j = \",j)\n",
    "#             ip1 = inputs[:,0,i,:,:,:]\n",
    "#             ip2 = inputs[:,1,i,:,:,:]\n",
    "#             ip3 = inputs[:,2,i,:,:,:]\n",
    "            ip = inputs[:,:,j,:,:,:].contiguous()\n",
    "#             ip = Variable(ip)\n",
    "            ip = Variable(ip).cuda()\n",
    "            label = labels[j].long()\n",
    "#             print(label)\n",
    "#             input()\n",
    "#             continue\n",
    "            label = Variable(label).cuda() \n",
    "#             label = Variable(label).view(1,1)\n",
    "            optimizer_model_2.zero_grad()\n",
    "\n",
    "            output = model_2(ip)\n",
    "            output = nn.Softmax()(output)\n",
    "#             if output >=0.5:\n",
    "#                 output = 1\n",
    "#                 output = Variable(output).cuda()\n",
    "#             else :\n",
    "#                 output = 0\n",
    "#                 output = Variable(output).cuda()\n",
    "#             output = 1*(output>=0.5)+0*(output<0.5))\n",
    "#             output = output\n",
    "            print(type(output),label)\n",
    "            input()\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer_model_2.step()\n",
    "\n",
    "            running_loss +=loss\n",
    "            loss_numpy=loss.cpu().data.numpy()        \n",
    "            epoch_loss +=loss_numpy\n",
    "    #             if count%100==0:\n",
    "    #                 print(\"count = \",count)\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d]  '%\n",
    "                  (epoch + 1, i + 1, ))\n",
    "            print(\"running loss = \",running_loss/500)\n",
    "            running_loss = 0.0\n",
    "            count=0\n",
    "    np.savez(\"epochVal\",epoch = epoch)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "\n",
    "        'state_dict': model_2.state_dict(),\n",
    "        'criterion': criterion.state_dict(),\n",
    "        'optimizer' : optimizer_model_2.state_dict()}, is_best=False,filename='trainedModel.pth.tar')\n",
    "# print('Finished Training')\n",
    "    epoch_lossArray.append(epoch_loss)\n",
    "end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "fig = plt.figure()\n",
    "plt.plot((np.array(epoch_lossArray)))\n",
    "plt.title(\"epoch loss \")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n",
    "fig.savefig(\"epoch_loss_trial.png\")\n",
    "save_checkpoint({\n",
    "        'epoch': num_epochs + 1,\n",
    "\n",
    "        'state_dict': model_2.state_dict(),\n",
    "        'criterion': criterion.state_dict(),\n",
    "        'optimizer' : optimizer_model_2.state_dict()}, is_best=False,filename='trainedModel_10_Class5.pth.tar')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_lossArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = 400\n",
    "Ylist = np.arange(0,400-42)\n",
    "Xlist = np.arange(0,400-42)\n",
    "xcoor = np.random.randint(42,400-42,10)\n",
    "ycoor = np.random.randint(42,400-42,10)\n",
    "\n",
    "for i in range(10):\n",
    "    Xlist[xcoor[i]-21:xcoor[i]+21] = 0\n",
    "    Ylist[ycoor[i]-21:ycoor[i]+21] = 0\n",
    "Xlist = np.unique(Xlist)\n",
    "Ylist = np.unique(Ylist)\n",
    "Xlist = Xlist[Xlist>=21]\n",
    "# for i in range(10):\n",
    "#     print(np.isin(np.arange(xcoor[i]-21,xcoor[i]+21),Xlist))\n",
    "# plt.plot(Xlist)\n",
    "# plt.show()\n",
    "print(Xlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "salDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/salImgs/\"\n",
    "rawDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/rawImgs/\"\n",
    "imgfiles=[]\n",
    "imgfiles2=[]\n",
    "imgfiles += [each for each in os.listdir(salDir) if each.endswith('.jpg')]\n",
    "imgfiles2 += [each for each in os.listdir(\"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/dataset1/rawImgs\") if each.endswith('.jpg')]\n",
    "print(imgfiles[0].split(\".\")[0][1:])\n",
    "\n",
    "# input()\n",
    "count = 0\n",
    "numPatches=5\n",
    "for file in imgfiles:\n",
    "    salImg = cv2.imread(salDir+file,0)\n",
    "    origImg = cv2.imread(rawDir+file.split(\".\")[0][1:]+\".jpg\")\n",
    "    imgS = cv2.resize(salImg,(150,150))\n",
    "    imgO1 = cv2.resize(origImg,(150,150))\n",
    "#     cv2.imshow(\"orig\",origImg)\n",
    "#     for j in [(400,400),(250,250),(150,150)]:\n",
    "#         print(j)\n",
    "    W=150\n",
    "        \n",
    "#         print(imgS.shape)\n",
    "    \n",
    "    YcoorP,XcoorP = np.nonzero(imgS>255*0.9)\n",
    "    print(XcoorP.size)\n",
    "    input()\n",
    "    YcoorP = YcoorP[YcoorP>21]\n",
    "    XcoorP = XcoorP[XcoorP>21]\n",
    "    print(XcoorP.size)\n",
    "    YcoorP = YcoorP[YcoorP<H-21]\n",
    "    XcoorP = XcoorP[XcoorP<W-21]\n",
    "    print(XcoorP.size)\n",
    "    input()\n",
    "    XcoorP = XcoorP[np.random.randint(XcoorP.shape[0], size=numPatches)]\n",
    "    YcoorP = YcoorP[np.random.randint(YcoorP.shape[0], size=numPatches)]\n",
    "    \n",
    "    YcoorN,XcoorN = np.nonzero(imgS<255*0.1)\n",
    "    YcoorN = YcoorN[YcoorN>21]\n",
    "    XcoorN = XcoorN[XcoorN>21]\n",
    "    YcoorN = YcoorN[YcoorN<H-21]\n",
    "    XcoorN = XcoorN[XcoorN<W-21]\n",
    "    XcoorN = XcoorN[np.random.randint(XcoorN.shape[0], size=numPatches)]\n",
    "    YcoorN = YcoorN[np.random.randint(YcoorN.shape[0], size=numPatches)]\n",
    "\n",
    "    label =[]\n",
    "    labelP =[]\n",
    "    labelN =[]\n",
    "    scale = [(150,150),(250,250),(400,400)]\n",
    "    imgO2 = cv2.resize(origImg,scale[1])\n",
    "    imgO3 = cv2.resize(origImg,scale[2])\n",
    "    imgArray = [imgO1,imgO2,imgO3]\n",
    "    for k in range(3):\n",
    "        \n",
    "        ycoorP = (YcoorP*scale[k][0]/150).astype(np.int8)\n",
    "        xcoorP = (XcoorP*scale[k][0]/150).astype(np.int8)\n",
    "        ycoorN = (YcoorN*scale[k][0]/150).astype(np.int8)\n",
    "        xcoorN = (XcoorN*scale[k][0]/150).astype(np.int8)\n",
    "        stack = []\n",
    "        imgO = imgArray[k]\n",
    "        for i in range(5):\n",
    "            \n",
    "            patchP1 = imgO[ycoorP[i]-21:ycoorP[i]+21,xcoorP[i]-21:xcoorP[i]+21]\n",
    "            patchP2 = cv2.flip(patchP1,0)\n",
    "            patchN1 = imgO[ycoorN[i]-21:ycoorN[i]+21,xcoorN[i]-21:xcoorN[i]+21]\n",
    "            patchN2 = cv2.flip(patchN1,0)\n",
    "            patchN1 = patchN1[np.newaxis,...]\n",
    "            patchN2 = patchN2[np.newaxis,...]\n",
    "            patchP1 = patchP1[np.newaxis,...]\n",
    "            patchP2 = patchP2[np.newaxis,...]\n",
    "            if i==0:\n",
    "                stack = np.concatenate((patchP1,patchP2),axis = 0)\n",
    "                stack = np.concatenate((stack,patchN1),axis = 0)\n",
    "                stack = np.concatenate((stack,patchN2),axis = 0)\n",
    "                label.append(1)\n",
    "                label.append(1)\n",
    "                label.append(0)\n",
    "                label.append(0)\n",
    "            else :\n",
    "                stack = np.concatenate((stack,patchP1),axis = 0)\n",
    "                stack = np.concatenate((stack,patchP2),axis = 0)\n",
    "                stack = np.concatenate((stack,patchN1),axis = 0)\n",
    "                stack = np.concatenate((stack,patchN2),axis = 0)\n",
    "                label.append(1)\n",
    "                label.append(1)\n",
    "                label.append(0)\n",
    "                label.append(0)\n",
    "        stack = (np.concatenate((Pstack,Nstack),axis= 0))[np.newaxis,...]\n",
    "        if k==0:\n",
    "            kstack = stack\n",
    "        else:\n",
    "            kstack = np.concatenate((kstack,stack),axis = 0)\n",
    "            \n",
    "    print(\"patch,shape = \",kstack.shape)\n",
    "    print(\"label len = \",len(label))\n",
    "    input()\n",
    "#             if count<=6480:\n",
    "#                 saveDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/train/\"\n",
    "#             else :\n",
    "#                 saveDir = \"/home/vijayraj/Workspace/Acads/EE698K/Project/dataset/test/\"\n",
    "                \n",
    "#             cv2.imwrite(saveDir + \"/1/\"+\"patchP_\"+str(count)+\".png\",patchP1)\n",
    "#             cv2.imwrite(saveDir + \"/0/\"+\"patchN_\"+str(count)+\".png\",patchN1)\n",
    "#             cv2.imwrite(saveDir + \"/1/\"+\"patchP_\"+str(count+1)+\".png\",patchP2)\n",
    "#             cv2.imwrite(saveDir + \"/0/\"+\"patchN_\"+str(count+1)+\".png\",patchN2)\n",
    "#             count= count+2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "5112*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(25)\n",
    "a= a[a>15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
